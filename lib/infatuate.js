// Generated by CoffeeScript 1.6.2
(function() {
  var Counter, DefaultDict, Distribution, LanguageModel, PUNCTUATION, WHITESPACES, add_space, all, binary_search, binary_search_aux, count_triplets, root, tokenize,
    __hasProp = {}.hasOwnProperty,
    __extends = function(child, parent) { for (var key in parent) { if (__hasProp.call(parent, key)) child[key] = parent[key]; } function ctor() { this.constructor = child; } ctor.prototype = parent.prototype; child.prototype = new ctor(); child.__super__ = parent.prototype; return child; },
    __indexOf = [].indexOf || function(item) { for (var i = 0, l = this.length; i < l; i++) { if (i in this && this[i] === item) return i; } return -1; };

  PUNCTUATION = /([\.,;!?])/g;

  WHITESPACES = /\s+/;

  tokenize = function(corpus) {
    corpus = corpus.replace(PUNCTUATION, " $1 ");
    corpus = corpus.replace(/(Mr|Mrs|Pr)\./g, "$1 ");
    corpus = corpus.replace(/("|--)/g, " ");
    return corpus.split(WHITESPACES);
  };

  DefaultDict = (function() {
    function DefaultDict(default_value) {
      this.default_value = default_value;
      this.c = {};
    }

    DefaultDict.prototype.get = function(k) {
      if (this.c[k] == null) {
        this.c[k] = this.default_value();
      }
      return this.c[k];
    };

    DefaultDict.prototype.set = function(k, v) {
      return this.c[k] = v;
    };

    DefaultDict.prototype.items = function() {
      var k, v, _ref, _results;

      _ref = this.c;
      _results = [];
      for (k in _ref) {
        v = _ref[k];
        _results.push([k, v]);
      }
      return _results;
    };

    return DefaultDict;

  })();

  Counter = (function(_super) {
    __extends(Counter, _super);

    function Counter() {
      this.c = {};
      this.default_value = function() {
        return 0;
      };
    }

    Counter.prototype.inc = function(k, count) {
      if (count == null) {
        count = 1;
      }
      return this.c[k] = this.get(k) + count;
    };

    return Counter;

  })(DefaultDict);

  binary_search_aux = function(arr, target, start, end) {
    var middle;

    if (arr[start] >= target) {
      return start;
    } else if ((end - start) <= 1) {
      return end;
    } else {
      middle = (start + end - (start + end) % 2) / 2;
      if (arr[middle] >= target) {
        return binary_search_aux(arr, target, start, middle);
      } else {
        return binary_search_aux(arr, target, middle, end);
      }
    }
  };

  binary_search = function(arr, target) {
    return binary_search_aux(arr, target, 0, arr.length);
  };

  Distribution = (function() {
    function Distribution(weights) {
      var value, weight, _i, _len, _ref;

      this.total = 0;
      this.values = [];
      this.boundaries = [];
      for (_i = 0, _len = weights.length; _i < _len; _i++) {
        _ref = weights[_i], value = _ref[0], weight = _ref[1];
        this.values.push(value);
        this.total += weight;
        this.boundaries.push(this.total);
      }
    }

    Distribution.prototype.draw = function() {
      var target, value_id;

      target = Math.random() * this.total;
      value_id = binary_search(this.boundaries, target);
      return this.values[value_id];
    };

    return Distribution;

  })();

  all = function(predicate, elements) {
    var el, _i, _len;

    for (_i = 0, _len = elements.length; _i < _len; _i++) {
      el = elements[_i];
      if (!predicate(el)) {
        return false;
      }
    }
    return true;
  };

  add_space = function(token) {
    if (__indexOf.call(".,", token) >= 0) {
      return token;
    } else {
      return " " + token;
    }
  };

  count_triplets = function(tokens) {
    var start, tok1, tok2, tok3, triplet_counter, _i, _ref, _ref1;

    triplet_counter = new DefaultDict((function() {
      return new DefaultDict((function() {
        return new Counter();
      }));
    }));
    for (start = _i = 0, _ref = tokens.length - 3; 0 <= _ref ? _i < _ref : _i > _ref; start = 0 <= _ref ? ++_i : --_i) {
      _ref1 = tokens.slice(start, start + 3), tok1 = _ref1[0], tok2 = _ref1[1], tok3 = _ref1[2];
      triplet_counter.get(tok1).get(tok2).inc(tok3);
    }
    return triplet_counter;
  };

  LanguageModel = (function() {
    function LanguageModel(trigrams, starting_bigrams) {
      this.trigrams = trigrams;
      this.starting_bigrams = starting_bigrams;
    }

    LanguageModel.prototype.draw_tokens = function() {
      var tokens, w1, w2, _ref, _ref1, _ref2;

      _ref = this.starting_bigrams.draw(), w1 = _ref[0], w2 = _ref[1];
      tokens = [w1, w2];
      while (w2 !== ".") {
        _ref1 = [w2, this.trigrams.get(w1)[w2].draw()], w1 = _ref1[0], w2 = _ref1[1];
        tokens.push(w2);
      }
      if ((3 < (_ref2 = tokens.length) && _ref2 < 20)) {
        return tokens;
      } else {
        return this.draw_tokens();
      }
    };

    LanguageModel.prototype.generate_sentence = function() {
      var token, tokens;

      tokens = this.draw_tokens();
      return ((function() {
        var _i, _len, _results;

        _results = [];
        for (_i = 0, _len = tokens.length; _i < _len; _i++) {
          token = tokens[_i];
          _results.push(add_space(token));
        }
        return _results;
      })()).join("").trim();
    };

    LanguageModel.prototype.generate_text = function(min_length) {
      var text;

      text = "";
      while (text.length < min_length) {
        text += this.generate_sentence() + " ";
      }
      return text;
    };

    return LanguageModel;

  })();

  if (typeof exports !== "undefined" && exports !== null) {
    root = exports;
  } else {
    this.infatuate = {};
    root = this.infatuate;
  }

  root.learn = function(text) {
    var bigram_distribution, bigrams, doublet_counter, k1, k2, markov_model, token_distribution, tokens, triplet_counter, w1, w2, word_count, word_counter, word_counts, _ref, _ref1, _ref2, _ref3;

    tokens = tokenize(text + ".");
    triplet_counter = count_triplets(tokens);
    markov_model = new DefaultDict(function() {
      return {};
    });
    _ref = triplet_counter.c;
    for (w1 in _ref) {
      doublet_counter = _ref[w1];
      _ref1 = doublet_counter.c;
      for (w2 in _ref1) {
        word_counts = _ref1[w2];
        token_distribution = new Distribution(word_counts.items());
        markov_model.get(w1)[w2] = token_distribution;
      }
    }
    bigrams = [];
    _ref2 = triplet_counter.get(".").c;
    for (k1 in _ref2) {
      word_counter = _ref2[k1];
      _ref3 = word_counter.c;
      for (k2 in _ref3) {
        word_count = _ref3[k2];
        bigrams.push([[k1, k2], word_count]);
      }
    }
    bigram_distribution = new Distribution(bigrams);
    return new LanguageModel(markov_model, bigram_distribution);
  };

}).call(this);
